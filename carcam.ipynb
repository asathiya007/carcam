{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and utilities\n",
    "import sys \n",
    "sys.path.insert(1, './object_detection')\n",
    "from models import *\n",
    "from utils import *\n",
    "import os, sys, time, datetime, random\n",
    "import cv2\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video utilities class \n",
    "class VideoUtils: \n",
    "    # extract frames from input video\n",
    "    def extract_frames(inputvid_filename):\n",
    "        video = cv2.VideoCapture(inputvid_filename)\n",
    "        frames = []\n",
    "        valid, frame = video.read()\n",
    "        while valid: \n",
    "            frames.append(frame)\n",
    "            valid, frame = video.read()\n",
    "        video.release()\n",
    "        return frames\n",
    "    \n",
    "    # generate a video from an array of frames \n",
    "    def compile_frames(frames, outputvid_filename):\n",
    "        height, width, layers = frames[0].shape\n",
    "        size = (width, height)\n",
    "        fps = 60\n",
    "        output_video = cv2.VideoWriter(outputvid_filename, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "        for frame in frames: \n",
    "            output_video.write(frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lane detection utilities class \n",
    "class LaneDetectionUtils: \n",
    "    # convert a color frame to a grayscale one\n",
    "    def _grayscale_frame(frame):\n",
    "        grayscale_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        return grayscale_frame\n",
    "    \n",
    "    # mask a frame to only include a region of interest\n",
    "    def _mask_frame(frame):\n",
    "        frame_height = frame.shape[0]\n",
    "        frame_width = frame.shape[1]\n",
    "        polygons = np.array([ \n",
    "            [(frame_width * 3 // 11, frame_height), (frame_width * 9 // 11, frame_height), (frame_width * 5 // 8, frame_height // 5 * 4), (frame_width * 3 // 7, frame_height // 5 * 4)] \n",
    "        ])\n",
    "        mask = np.zeros_like(frame) \n",
    "        cv2.fillPoly(mask, polygons, 255)\n",
    "        masked_frame = cv2.bitwise_and(frame, mask)\n",
    "        return masked_frame\n",
    "    \n",
    "    # threshold frame to emphasize lane lines \n",
    "    def _threshold_frame(frame):\n",
    "        ret, thresholded_frame = cv2.threshold(frame, 40, 145, cv2.THRESH_BINARY)\n",
    "        return thresholded_frame\n",
    "    \n",
    "    # determine start and end points for lane marker\n",
    "    def _mark_lane_points(frame, params):\n",
    "        slope, intercept = params[0], params[1]\n",
    "        y1 = frame.shape[0]\n",
    "        y2 = int(y1 * 4 / 5)\n",
    "        x1 = int((y1 - intercept) / slope)\n",
    "        x2 = int((y2 - intercept) / slope)\n",
    "        return np.array([x1, y1, x2, y2])\n",
    "    \n",
    "    # find both lane lines and and their marker points\n",
    "    def _find_lane_lines(frame, lines):\n",
    "        left_lane_fit, right_lane_fit = [], []\n",
    "        if lines is None: \n",
    "            return None\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            parameters = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope, intercept = parameters[0], parameters[1]\n",
    "            if slope < 0: \n",
    "                left_lane_fit.append((slope, intercept))\n",
    "            else: \n",
    "                right_lane_fit.append((slope, intercept))\n",
    "        left_lane_avgfit = np.average(left_lane_fit, axis=0)\n",
    "        if np.any(np.isnan(left_lane_avgfit)): \n",
    "            return None\n",
    "        left_lane_line = LaneDetectionUtils._mark_lane_points(frame, left_lane_avgfit)\n",
    "        right_lane_avgfit = np.average(right_lane_fit, axis=0)\n",
    "        if np.any(np.isnan(right_lane_avgfit)): \n",
    "            return None\n",
    "        right_lane_line = LaneDetectionUtils._mark_lane_points(frame, right_lane_avgfit)\n",
    "        return np.array([left_lane_line, right_lane_line])\n",
    "    \n",
    "    # draw lane lines on the image\n",
    "    def _draw_lane_lines(frame, lane_lines): \n",
    "        lane_line_frame = np.zeros_like(frame)\n",
    "        if lane_lines is not None: \n",
    "            for x1, y1, x2, y2 in lane_lines:\n",
    "                try: \n",
    "                    cv2.line(lane_line_frame, (x1, y1), (x2, y2), (252, 173, 76), 10)\n",
    "                except: \n",
    "                    return None\n",
    "        return lane_line_frame\n",
    "    \n",
    "    # return an array of frames with lanes detected\n",
    "    def detect_lanes(frames):\n",
    "        lane_detected_frames = []\n",
    "        for frame in frames: \n",
    "            grayscaled_frame = LaneDetectionUtils._grayscale_frame(frame)\n",
    "            masked_frame = LaneDetectionUtils._mask_frame(grayscaled_frame)\n",
    "            thresholded_frame = LaneDetectionUtils._threshold_frame(masked_frame)\n",
    "            detected_lines = cv2.HoughLinesP(thresholded_frame, 2, np.pi / 180, 100, np.array([]), minLineLength = 10, maxLineGap = 5)\n",
    "            lane_lines = LaneDetectionUtils._find_lane_lines(frame, detected_lines)\n",
    "            if lane_lines is None: \n",
    "                lane_detected_frames.append(frame)\n",
    "                continue\n",
    "            annotated_frame = LaneDetectionUtils._draw_lane_lines(frame, lane_lines)\n",
    "            if annotated_frame is None: \n",
    "                lane_detected_frames.append(frame)\n",
    "                continue\n",
    "            combined_frame = cv2.addWeighted(frame, 0.8, annotated_frame, 1, 1)\n",
    "            lane_detected_frames.append(combined_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        return lane_detected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure object detection model \n",
    "config_path = 'object_detection/config/yolov3.cfg'\n",
    "weights_path = 'object_detection/config/yolov3.weights'\n",
    "class_path = 'object_detection/config/coco.names'\n",
    "image_size = 416\n",
    "conf_thres = 0.8\n",
    "nms_thres = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/carcam/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# load model and weights\n",
    "model = Darknet(config_path, img_size=image_size)\n",
    "model.load_weights(weights_path)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "classes = load_classes(class_path)\n",
    "Tensor = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# road entity detection utilities class \n",
    "class RoadEntityDetectionUtils:\n",
    "    # road entities to detect\n",
    "    road_entities = set([\n",
    "        'person', \n",
    "        'bicycle', \n",
    "        'car', \n",
    "        'truck', \n",
    "        'motorcycle', \n",
    "        'bus', \n",
    "        'train', \n",
    "        'boat', \n",
    "        'skis',\n",
    "        'snowboard'\n",
    "        'skateboard',\n",
    "        'surfboard'\n",
    "    ])\n",
    "\n",
    "    # preprocess image \n",
    "    def _preprocess_image(image):\n",
    "        ratio = min(image_size / image.size[0], image_size / image.size[1])\n",
    "        image_width = round(image.size[0] * ratio)\n",
    "        image_height = round(image.size[1] * ratio)\n",
    "        image_transforms = transforms.Compose([\n",
    "            transforms.Resize((image_height, image_width)),\n",
    "            transforms.Pad(\n",
    "                (\n",
    "                    max(int((image_height - image_width) / 2), 0), \n",
    "                    max(int((image_width - image_height) / 2), 0), \n",
    "                    max(int((image_height - image_width) / 2), 0),\n",
    "                    max(int((image_width - image_height) / 2), 0)\n",
    "                ), \n",
    "                (128, 128, 128)\n",
    "            ),\n",
    "            transforms.ToTensor()\n",
    "         ])\n",
    "        image_tensor = image_transforms(image).float()\n",
    "        image_tensor = image_tensor.unsqueeze_(0)\n",
    "        input_image = Variable(image_tensor.type(Tensor))\n",
    "        return input_image\n",
    "    \n",
    "    # find road entities in image \n",
    "    def _find_road_entities(image):\n",
    "        input_image = RoadEntityDetectionUtils._preprocess_image(image)\n",
    "        with torch.no_grad(): \n",
    "            detections = model(input_image)\n",
    "            detections = non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
    "        return detections[0]\n",
    "    \n",
    "    # detect road entities in frame\n",
    "    def detect_road_entities(frames):\n",
    "        road_entity_detected_frames = []\n",
    "        for frame in frames: \n",
    "            image = Image.fromarray(frame)\n",
    "            detections = RoadEntityDetectionUtils._find_road_entities(image)\n",
    "            image = np.array(image)\n",
    "            padding_x = max(image.shape[0] - image.shape[1], 0) * (image_size / max(image.shape))\n",
    "            padding_y = max(image.shape[1] - image.shape[0], 0) * (image_size / max(image.shape))\n",
    "            unpadded_height, unpadded_width = image_size - padding_y, image_size - padding_x\n",
    "            if detections is not None:\n",
    "                tracked_road_entities = detections.cpu().detach().numpy()\n",
    "                unique_labels = detections[:, -1].cpu().unique()\n",
    "                num_class_preds = len(unique_labels.detach().cpu().numpy())\n",
    "                for x1, y1, x2, y2, _, _, class_pred in tracked_road_entities: \n",
    "                    box_height = int(((y2 - y1) / unpadded_height) * image.shape[0])\n",
    "                    box_width = int(((x2 - x1) / unpadded_width) * image.shape[1])\n",
    "                    y1 = int(((y1 - padding_y // 2) / unpadded_height) * image.shape[0])\n",
    "                    x1 = int(((x1 - padding_x // 2) / unpadded_width) * image.shape[1])\n",
    "                    class_name = classes[int(class_pred)]\n",
    "                    if class_name in RoadEntityDetectionUtils.road_entities: \n",
    "                        collision_risk = False\n",
    "                        if collision_risk:\n",
    "                            color = (0, 0, 255, 1.0)\n",
    "                        else: \n",
    "                            color = (103, 230, 114, 1.0)\n",
    "                        cv2.rectangle(frame, (x1, y1), (x1 + box_width, y1 + box_height), color, 4)\n",
    "                        cv2.rectangle(frame, (x1, y1 - 35), (x1 + len(class_name) * 19, y1), color, -1)\n",
    "                        cv2.putText(frame, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 3)\n",
    "            road_entity_detected_frames.append(frame)\n",
    "        return road_entity_detected_frames            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CarCam computer vision pipeline\n",
    "def carcam_pipeline(inputvid_filename, outputvid_filename):\n",
    "    print('Input video: {}'.format(inputvid_filename))\n",
    "    print('Executing CarCam computer vision pipeline. Please wait...')\n",
    "    frames = VideoUtils.extract_frames(inputvid_filename)\n",
    "    lane_detection_frames = LaneDetectionUtils.detect_lanes(frames)\n",
    "    road_entity_detection_frames = RoadEntityDetectionUtils.detect_road_entities(lane_detection_frames)\n",
    "    VideoUtils.compile_frames(road_entity_detection_frames, outputvid_filename)\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Output video: {}'.format(outputvid_filename))\n",
    "    print('All done, check out your output video!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input video: input.mov\n",
      "Executing CarCam computer vision pipeline. Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/carcam/lib/python3.7/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda3/envs/carcam/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output video: output.mp4\n",
      "All done, check out your output video!\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "carcam_pipeline('input.mov', 'output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
